{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt0z11mqV3vQ0dy0Fb8Apd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryAlexandrovv/infopoisk/blob/master/task5/task5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK9OhkZoCg7p",
        "outputId": "6a119cb8-05d1-4cef-c55f-6b85973d608d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=735a0a6afbb4fc0b9a0629775504fbf471b57f7c50185521f3733aa6843e38d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoPjOGrq-xmY",
        "outputId": "64309acb-b558-4b6d-f468-b8aa9453a5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "{3: 0.9526201351759274, 11: 0.9455739500126588, 12: 0.9455739500126588, 21: 0.9455739500126588, 7: 0.9455739500126586, 9: 0.9455739500126586, 15: 0.9455739500126586, 18: 0.9455739500126586, 5: 0.9455739500126585, 8: 0.9455739500126585, 10: 0.9455739500126585, 13: 0.9455739500126585, 14: 0.9455739500126585, 20: 0.9455739500126585, 4: 0.9455739500126584, 6: 0.9455739500126584, 16: 0.9455739500126584, 17: 0.9455739500126584, 19: 0.9455739500126584, 27: 0.9411110156279419, 30: 0.9411110156279419, 31: 0.9411110156279419, 35: 0.9411110156279419, 36: 0.9411110156279419, 45: 0.9411110156279419, 57: 0.9411110156279419, 63: 0.9411110156279419, 22: 0.9411110156279417, 23: 0.9411110156279417, 24: 0.9411110156279417, 25: 0.9411110156279417, 26: 0.9411110156279417, 29: 0.9411110156279417, 32: 0.9411110156279417, 38: 0.9411110156279417, 39: 0.9411110156279417, 49: 0.9411110156279417, 50: 0.9411110156279417, 51: 0.9411110156279417, 55: 0.9411110156279417, 58: 0.9411110156279417, 59: 0.9411110156279417, 28: 0.9411110156279416, 33: 0.9411110156279416, 34: 0.9411110156279416, 37: 0.9411110156279416, 40: 0.9411110156279416, 41: 0.9411110156279416, 42: 0.9411110156279416, 43: 0.9411110156279416, 44: 0.9411110156279416, 46: 0.9411110156279416, 47: 0.9411110156279416, 48: 0.9411110156279416, 53: 0.9411110156279416, 54: 0.9411110156279416, 56: 0.9411110156279416, 60: 0.9411110156279416, 61: 0.9411110156279416, 52: 0.9411110156279415, 67: 0.929812176496718, 64: 0.9298121764967178, 65: 0.9298121764967177, 66: 0.9298121764967177, 74: 0.9251010803450889, 69: 0.9251010803450888, 70: 0.9251010803450888, 71: 0.9251010803450888, 75: 0.9251010803450888, 68: 0.9251010803450886, 72: 0.9251010803450886, 73: 0.9251010803450886, 76: 0.9251010803450886, 77: 0.9251010803450886, 83: 0.9213149553971376, 81: 0.9213149553971375, 84: 0.9213149553971375, 78: 0.9213149553971374, 79: 0.9213149553971374, 80: 0.9213149553971374, 82: 0.9213149553971374, 85: 0.9213149553971374, 86: 0.9213149553971374, 87: 0.9213149553971374, 88: 0.9213149553971373, 89: 0.9181546244561191, 93: 0.9181546244561191, 97: 0.9181546244561191, 94: 0.918154624456119, 95: 0.918154624456119, 96: 0.918154624456119, 91: 0.9181546244561188, 92: 0.9181546244561188, 90: 0.9181546244561187, 98: 0.9154493510140883, 99: 0.9154493510140883, 1: 0.9113938145859378, 0: 0.9113938145859377, 2: 0.9113938145859377}\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "import os\n",
        "\n",
        "import pymorphy2\n",
        "from numpy import dot\n",
        "from numpy.dual import norm\n",
        "import glob\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def calc_cos_similarity(query_tf_idf_vector, document_tf_idf_vector):\n",
        "    query_vector = list(query_tf_idf_vector.values())\n",
        "    movie_vector = list(document_tf_idf_vector.values())\n",
        "\n",
        "    if norm(query_vector) == 0 or norm(movie_vector) == 0:\n",
        "        return 0\n",
        "\n",
        "    return dot(query_vector, movie_vector) / (norm(query_vector) * norm(movie_vector))\n",
        "\n",
        "def search(query):\n",
        "    query_words = []\n",
        "    for word in query.split():\n",
        "        query_words.append(morph_analyzer.parse(word)[0].normal_form)\n",
        "    unique_query_words= set(query_words)\n",
        "\n",
        "    query_tf_vector = {}\n",
        "\n",
        "    for term in unique_query_words:\n",
        "        word_count_in_query = len([x for x in query_words if x == term])\n",
        "        query_tf_vector.update({term: {'tf': word_count_in_query / len(query_words)}})\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    for i, lines in lemmas_tf_idf_vector.items():\n",
        "        document_tf_idf_vector = {}\n",
        "        query_tf_idf_vector = {}\n",
        "        query_terms = []\n",
        "\n",
        "        for line in lines:\n",
        "            line_data = line.split()\n",
        "            term = line_data[0]\n",
        "            idf = line_data[1]\n",
        "            tf_idf = line_data[2]\n",
        "\n",
        "            if term in unique_query_words:\n",
        "                query_terms.append(term)\n",
        "                query_tf_idf_vector[term] = query_tf_vector.get(term).get('tf') * float(idf)\n",
        "                document_tf_idf_vector[term] = float(tf_idf)\n",
        "\n",
        "        for term in unique_query_words:\n",
        "            if term not in query_terms:\n",
        "                query_tf_idf_vector[term] = 1\n",
        "                document_tf_idf_vector[term] = 0\n",
        "\n",
        "        cos_sim = calc_cos_similarity(query_tf_idf_vector, document_tf_idf_vector)\n",
        "        if cos_sim != 0:\n",
        "            result[i] = cos_sim\n",
        "\n",
        "    sorted_result = sorted(result.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    result = dict(sorted_result)\n",
        "    return result\n",
        "\n",
        "morph_analyzer = pymorphy2.MorphAnalyzer()\n",
        "lemmas_tf_idf_vector = {}\n",
        "\n",
        "k = 100\n",
        "for i in range(0, k):\n",
        "    with open('drive/MyDrive/dz/lemmas_tf_idf/page-' + str(i) + '.txt') as file:\n",
        "        lemmas_tf_idf_vector[i] = file.readlines()\n",
        "\n",
        "print(search('Лайфхаки и рыба'))"
      ]
    }
  ]
}